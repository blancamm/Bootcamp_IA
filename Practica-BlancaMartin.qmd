---
format: html
editor: visual
  markdown: 
    wrap: 72
---

Vasmos a cargar el dataset de AirBnB descargado de [aquí](https://public.opendatasoft.com/explore/dataset/airbnb-listings/export/?disjunctive.host_verifications&disjunctive.amenities&disjunctive.features&q=Madrid&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQ09VTlQiLCJ5QXhpcyI6Imhvc3RfbGlzdGluZ3NfY291bnQiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiJyYW5nZS1jdXN0b20ifV0sInhBeGlzIjoiY2l0eSIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6IiIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJyb29tX3R5cGUiLCJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1saXN0aW5ncyIsIm9wdGlvbnMiOnsiZGlzanVuY3RpdmUuaG9zdF92ZXJpZmljYXRpb25zIjp0cnVlLCJkaXNqdW5jdGl2ZS5hbWVuaXRpZXMiOnRydWUsImRpc2p1bmN0aXZlLmZlYXR1cmVzIjp0cnVlfX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=16,41.38377,2.15774&basemap=jawg.streets)

![](descargar.png)

```{r}
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)

```

```{r}
library("dplyr")
library("lubridate")
```

1.  Vamos a quedarnos con las columnas de mayor interés: 'City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude' Nos quedarmos solo con las entradas de Madrid para Room.Type=="Entire home/apt" y cuyo barrio (Neighbourhood) no está vacio '' Podemos eliminar las siguientes columnas que ya no son necesarias: "Room.Type",'City' Llama a nuevo dataframe df_madrid.

    ```{r}
    airbnb |> select('City','Room.Type','Neighbourhood','Accommodates','Bathrooms',
                     'Bedrooms','Beds','Price','Square.Feet',
                     'Guests.Included','Extra.People','Review.Scores.Rating',
                     'Latitude', 'Longitude' ) -> airbnb
    airbnb |> filter (City=="Madrid" & Room.Type=="Entire home/apt" &  Neighbourhood != "")|> select(-Room.Type, -City)-> df_madrid
    (df_madrid)
    ```

------------------------------------------------------------------------

2.  Crea una nueva columna llamada Square.Meters a partir de Square.Feet. Recuerda que un pie cuadrado son 0.092903 metros cuadrados.

    ```{r}
    df_madrid$Square.Meters<- df_madrid$Square.Feet*0.092903
    df_madrid
    ```

------------------------------------------------------------------------

3.  ¿Que porcentaje de los apartamentos no muestran los metros cuadrados? Es decir, ¿cuantos tienen NA en Square.Meters?

    ```{r}
    numero_na <- length(which(is.na(df_madrid$Square.Meters)==T))
    numero_total <- length(df_madrid$Square.Meters)
    porcentaje_na <- numero_na/numero_total
    paste("El porcentaje de NA en la columna metros cuadrados es:", porcentaje_na*100, '%')
    ```

------------------------------------------------------------------------

4.  De todos los apartamentos que tienen un valor de metros cuadrados diferente de NA ¿Que porcentaje de los apartamentos tienen 0 metros cuadrados?

    ```{r}
    numero_0 <- length(which(is.na(df_madrid$Square.Meters)==F & df_madrid$Square.Meters==0))
    numero_total <- length(df_madrid$Square.Meters)
    porcentaje_0 <- numero_0/numero_total
    paste("El porcentaje de 0s en la columna metros cuadrados es:", porcentaje_0*100, '%')
    ```

------------------------------------------------------------------------

5.  Reemplazar todos los 0m\^2 por NA

    ```{r}
    df_madrid$Square.Meters[which(df_madrid$Square.Meters==0)]<- NA

    df_madrid
    ```

------------------------------------------------------------------------

Hay muchos NAs, vamos a intentar crear un modelo que nos prediga cuantos son los metros cuadrados en función del resto de variables para tratar de rellenar esos NA. Pero **antes de crear el modelo** vamos a hacer: \* pintar el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más. \* crear una variable sintética nueva basada en la similitud entre barrios que usaremos en nuestro modelo.

6.  Pinta el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más

    ```{r}
    library("ggplot2")
    ggplot(df_madrid, aes(x = Square.Meters)) +
      geom_histogram(binwidth = 5 , fill = "skyblue", color = "black" )+geom_vline(xintercept = 20, color="red")  + xlab("Metros cuadrados")+ylab("Frecuencia")
    ```

------------------------------------------------------------------------

7.  Asigna el valor NA a la columna Square.Meters de los apartamentos que tengan menos de 20 m\^2

    ```{r}
    df_madrid$Square.Meters[which(df_madrid$Square.Meters<20)]<- NA
    df_madrid
    ```

------------------------------------------------------------------------

8.  Existen varios Barrios que todas sus entradas de Square.Meters son NA, vamos a eliminar del dataset todos los pisos que pertenecen a estos barrios.

    ```{r}

    df_madrid |> group_by(Neighbourhood) |> summarise(num = n() ,todos_na = all(is.na(Square.Meters)) ) |> filter (todos_na==T) |> pull (Neighbourhood) -> Barrios_todo_na


    df_madrid |> filter (!(Neighbourhood %in% Barrios_todo_na)) -> df_madrid


    ```

    ------------------------------------------------------------------------

9.  ¿Tienen todos los barrios los mismos metros cuadrados de media? ¿Con que test lo comprobarías?

    ------------------------------------------------------------------------

    ```{r}
    # Para comparar si la media de metros cuadrados en los distintos barrios es la misma, se tendria que hacer un test ANOVA, donde la hipotesis nula asume que las medias de los grupos a comparar son iguales. Se aplica anova cuando los grupos siguen distibuciones gaussianas. Se hace un test de shapiro primero para comprobar que esto es así:
    barrios <- sort(unique(df_madrid$Neighbourhood))

    contador_barrios_normales <- 0
    contador_barrios_testeados <- 0
    contador_barrios_sin_datos <- 0
    for (barrio in barrios){
      datos_barrio <- df_madrid$Square.Meters[df_madrid$Neighbourhood==barrio]
      datos_barrio <- na.omit(datos_barrio)
      contador_barrios_testeados <- contador_barrios_testeados +1
      
      if (length(datos_barrio) >= 3) {
        pval <- shapiro.test(datos_barrio)$p.value
        print(paste("Barrio:", barrio, "- p-value:", pval))
        
        if (pval>0.05) {contador_barrios_normales <- contador_barrios_normales + 1}
        } 
      else { contador_barrios_sin_datos <- contador_barrios_sin_datos+1
        print(paste("Barrio:", barrio, "No hay suficientes datos para realizar test de Shapiro"))
      }
    }

    porcentaje_normales <- (contador_barrios_normales / contador_barrios_testeados) *100
    porcentaje_sin_datos <- (contador_barrios_sin_datos / contador_barrios_testeados) *100
    cat("\nPorcentaje de barrios con distribución normal:", round(porcentaje_normales, 2), "%\n")
    cat("\nPorcentaje de barrios sin suficientes datos:", round(porcentaje_sin_datos, 2), "%\n")


    ```

    ```{r}
    #Como hemos visto que la mayoria de los barrios no tienen datos suficientes para comprobar (mas de la mitad), y aunque si es cierto que dentro de los sobrantes con sufcientes datos, más de la mitad siguen una distribución normal, se decide hacer un test de Kruskal-Wallis, en vez de anova, donde no se asume que los datos sigan ningun tipo de distribucion.

    kruskal.test(Square.Meters ~ Neighbourhood, data=df_madrid)

    # Como se ve, y se esperaría viendo la diversidad de los grupos en el shapiro test, el p-value de kruskal-wallis test es menor que 0.05, lo que significa que las medias no son iguales para cada barrio. No todos los barrios siguen la misma distribción de mteros cuadrados. Ahora tendríamos que ver cual de ellos son los que difieren significativamente.
    ```

10. Vamos a agrupar los barrios por metros cuadrados. Podemos usar una matriz de similaridad de Tukey. Muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos. ¿Como se diferencia la media del Barrio A al Barrio B? (Es decir, cual sería el pvalor suponiendo una H0 en la que las medias son iguales)

    ```{r, fig.width=20, fig.height=20}

    #Para ver como de similares son las medias de los metros cuadrados de cada barrio por parejas, hacemos un matriz de similiaridad de Tukey, pasando por alto que se basa en anova.


    aov_result <- aov(Square.Meters ~ Neighbourhood, data = df_madrid, na.action = na.omit)
    tukey <- TukeyHSD(aov_result)
    tukey_result <- data.frame(tukey$Neighbourhood)

    #Crear matriz
    barrios <- sort(unique(df_madrid$Neighbourhood))
    resm <- matrix(NA, length(barrios), length(barrios))
    rownames(resm) <- barrios
    colnames(resm) <- barrios

    #Rellenar matriz
    resm[lower.tri(resm)] <- round(tukey_result$p.adj, 4)
    resm[upper.tri(resm)] <- t(resm)[upper.tri(resm)]
    diag(resm) <- 1

    #Grafica
    library(ggplot2)
    library(reshape2)

    dfResm <- melt(resm)

    ggplot(dfResm, aes(x = Var1, y = Var2, fill = value)) +
      geom_tile(colour = "black") +
      geom_text(aes(label = paste0(round(value * 100, 0), "%")), size = 5) +
      scale_fill_gradient(low = "white", high = "darkblue") +
      ylab("Barrio") + xlab("Barrio") +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 90, hjust = 1, size =25), 
        axis.text.y = element_text(size = 25),
            legend.position = "none")


    #Se puede ver en la figura de abajo, que aquel barrio que realmente destaca es 'Jeronimos' pues la mayoria de sus valores al emparejarse con el resto de de barrios es menor de 5%. Es decir, su p-values < 0.05, lo que quiere decir que hay una diferencia significativa de la media de metros cuadrados en el barrio jeronimos, con rspecto al resto de barrios. El barrio de rio Rosas también destaca, pero sus valores no llegan a ser significativos.--+++
    ```

------------------------------------------------------------------------

11. En el punto anterior has creado una matriz de p-valores que indica como de parecidos son dos barrios. Si su pvalor es bajo significa que los barrios son diferentes, si es alto significa que los barrios se parecen. Esta matriz la podemos usar como matriz de distancia si restamos el pvalor a 1. Es decir si usamos como distancia 1-pvalor. De esta forma barrios con un pvalor alto tendrán una distancia mayor que aquellos con un pvalor bajo. Usando esta última métrica como matriz de distancias dibuja un dendrograma de los diferentes barrios.

```{r}
library(dendextend)

distancias <- 1 - resm #Asi si el p-valor es muy pequeño (significativo) la distancia es mayor
matriz_disatncia <- as.dist(distancias)

barrios.tree <- hclust(matriz_disatncia, method="complete")
barrios.dend <- as.dendrogram(barrios.tree) 


clusters <- cutree(barrios.dend, h=0.75)
plot(color_branches(barrios.dend, h=0.75),leaflab="none")

```

------------------------------------------------------------------------

10. ¿Que punto de corte sería el aconsejable?, ¿cuantos clusters aparecen?

```{r}
#Como hemos visto en el dendrograma, se puede ver que hay 3 grupos grandes. Basandonos en el eje y para ver las alturas, decidimos que el corte es en h=0.4, consiguiendo tres clusters

#Revision tras el modelo: se vio que id:2 no aportaba informacion relevante (coeficiente no significativo) por lo que se ha aumentado el h para tener tan solo dos tipos de cluters. Ademas esto tambien tenia mas sentido viendo la matriz de tukey, pues la diferencia es significativa en tan solo dos barrios

clusters

str(clusters)
attributes(clusters)

```

------------------------------------------------------------------------

11. Vamos a crear una nueva columna en el dataframe df_madrid con un nuevo identificador marcado por los clusters obtenidos. Esta columna la llamaremos neighb_id

```{r}
df_madrid$neighb_id <- clusters[df_madrid$Neighbourhood]

df_madrid$neighb_id <- as.factor(df_madrid$neighb_id)
df_madrid
```

------------------------------------------------------------------------

12. Vamos a crear dos grupos, uno test y otro train.

    ```{r}
    #Ahora pasamos a crear un modelo que prediga los metros cuadradas en funcion del resto de variables del datafrmae. Pero lo primero es chequear la correlacion que hay entre estas variables:
    library(GGally)

    str(df_madrid) #Para chequear que columanas queremos buscar la correlacion

    #Hacemos matriz de correlacion como en clase
    numericas <- df_madrid[, sapply(df_madrid, is.numeric)] #con "is.numeric" cogemos solo los numeros
    options(repr.plot.height = 25, repr.plot.width = 25)
    ggpairs(numericas,
            lower = list(continuous = wrap("points", alpha = 0.3, size = 0.1, color = 'blue')),
            upper = list(continuous = wrap("cor", size = 3)),
            diag = list(continuous = wrap("densityDiag")))

    #Otra manera de hacer la matriz, más visualmente clara:
    library(corrplot)
    corr_matrix <- cor(numericas, use = "complete.obs")
    corrplot(corr_matrix, method = "color", type = "upper", tl.cex = 0.7)
    ```

------------------------------------------------------------------------

13. Tratamos de predecir los metros cuadrados en función del resto de columnas del dataframe.

```{r}
#Basandonos en los gráficos que acabamos de ver, podemos ver, como esperado que Square.feet y Square.meters estan relacionado 1. Pero tambine que Bed y accomodates esta muy relacionado, y que por ejemplo latitude, longitude no tiene ningun tipo de relacion. además puede estar relacionados con el barrio tambien.

#Creamos dos grupos

set.seed(1459)  # Para reproducibilidad
train_indices <- sample(1:nrow(df_madrid), 0.7 * nrow(df_madrid))
train_data <- df_madrid[train_indices, ]
test_data <- df_madrid[-train_indices, ]


#Creamos el modelo 
#Basandonos en la matriz correlacion, vemos que beds y accomodates estan bastante relacionados (1º se prueba con ambas). Así como Square.feets y square.meters como era de esperar. También vemos que no tienen casi relación latitude y longitude, y que no tienen mucho sentido en cuanto a nuestros datos. Los barrios tampoco han de ponerse porque hay ciertos de ellos que no tienen muchos valores.

modelo_metros_cuadrados <- lm(Square.Meters ~ Accommodates + Bathrooms + Bedrooms + Beds + Price + Guests.Included + Extra.People + Review.Scores.Rating + neighb_id, 
             data = train_data)

summary(modelo_metros_cuadrados)
```

------------------------------------------------------------------------

14. Evaluar la calidad de vuestro modelo

```{r}
train_data$metros_estimados <- predict(modelo_metros_cuadrados, newdata = train_data)
test_data$metros_estimados <- predict(modelo_metros_cuadrados, newdata = test_data)

caret::postResample(pred = train_data$metros_estimados, obs = train_data$Square.Meters)
caret::postResample(pred = test_data$metros_estimados, obs = test_data$Square.Meters)

#Pintamos los residuos
ggplot(train_data, aes(x = Square.Meters, y = Square.Meters - metros_estimados)) +
  geom_point(alpha = 0.3) + ylab("Residuo") + xlab("Valor real") + ggtitle("Residuos en la training data")

ggplot(test_data, aes(x = Square.Meters, y = Square.Meters - metros_estimados)) +
  geom_point(alpha = 0.3, color = 'red') + ylab("Residuo") + xlab("Valor real") + ggtitle("Residuos en el test")


#Como lo interesante son los residuos del test para saber si sabe generalizar.
residuos_test <- test_data$Square.Meters - test_data$metros_estimados
hist(residuos_test, breaks = 20, main = "Histograma de los residuos de test", xlab = "Residuo", col = "skyblue", border = "black")
qqnorm(residuos_test)
qqline(residuos_test, col = "orange", lwd = 2)


```

------------------------------------------------------------------------

```{r}
#Como parece que con este primer test los resultados no han sido idoneos, repetimos el modelo y chequeamos de nuevo

#Parece que RMSE y NAE sale NA, porque al predecir se utiliza data que tiene NA en algunos de sus valores. Debido a esto se añade una fila para solo coger las filas con NA completos. También se elimina la variable Beds, que se vio en la matriz de correlacion que estaba muy relacionada con accommodates
#Se hizo también el intento de quitar Review.Scores.Rating (al ser poco significativo y la correlacion baja), pero daba peores valores de RMSE en el testing

variables_modelo <- c("Square.Meters", "Accommodates", "Bathrooms", "Bedrooms", "Price", "Guests.Included", "Extra.People", "neighb_id", "Review.Scores.Rating")

df_madrid_model <- df_madrid[complete.cases(df_madrid[, variables_modelo]), ]

#Creamos dos grupos
set.seed(1459)  # Para reproducibilidad
train_indices <- sample(1:nrow(df_madrid_model), 0.7 * nrow(df_madrid_model))
train_data <- df_madrid_model[train_indices, ]
test_data <- df_madrid_model[-train_indices, ]


modelo_metros_cuadrados <- lm(Square.Meters ~ Accommodates+Bathrooms+ Bedrooms+Price+Guests.Included+ Extra.People+ neighb_id +  Review.Scores.Rating, data = train_data)

summary(modelo_metros_cuadrados)
```

```{r}
#Revaluamos el modelo

train_data$metros_estimados <- predict(modelo_metros_cuadrados, newdata = train_data)
test_data$metros_estimados <- predict(modelo_metros_cuadrados, newdata = test_data)

caret::postResample(pred = train_data$metros_estimados, obs = train_data$Square.Meters)
caret::postResample(pred = test_data$metros_estimados, obs = test_data$Square.Meters)

#Pintamos los residuos
ggplot(train_data, aes(x = Square.Meters, y = Square.Meters - metros_estimados)) +
  geom_point(alpha = 0.3) + ylab("Residuo") + xlab("Valor real") + ggtitle("Residuos en la training data")

ggplot(test_data, aes(x = Square.Meters, y = Square.Meters - metros_estimados)) +
  geom_point(alpha = 0.3, color = 'red') + ylab("Residuo") + xlab("Valor real") + ggtitle("Residuos en el test")


#Como lo interesante son los residuos del test para saber si sabe generalizar.
residuos_test <- test_data$Square.Meters - test_data$metros_estimados
qqnorm(residuos_test)
qqline(residuos_test, col = "orange", lwd = 2)
hist(residuos_test, breaks = 20, main = "Histograma de los residuos de test", xlab = "Residuo", col = "skyblue", border = "black")

```

\

```{r}
#En este ultimo modelo se puede ver que la mayoria de los coeficientes son significativos, y que la R^2 es mayor que 0.5 en el grupo test. Lo que nos indica un buena generalizacion. Es cierto que el valor de test de RMSE es mayor que el de training lo que nos indica que hay un poco de overfitting (tal vez se podria quitar la variable price, o mas bien una que relaciona bedrooms y acccommodates).
#Tambien se puede ver con el qqnorm, que los residuos de test no siguen una distribución entera, parecen dispersos y con mucha varianza. Por eso se hace una distancia de cooks. Creo que en esta se ve los valores que que ya en el histrograma del pricnipio se podrian filtar pues eran muy grandes.

plot(cooks.distance(modelo_metros_cuadrados))
abline(h = 0.15, col = "red", lty = 2)
# se intenta coger solo la linea del principio. Porque aunque hay dos claros outliers, los otros tres seguramenre no destaquen tanto por la escala del eje y. Como en el ejemplo en clase 0.15 parece buen threshold

"train_data_clean<-train_data[cooks.distance(modelo_metros_cuadrados)<0.15,]
modelo_metros_cuadrados_filtrado<-lm(Square.Meters ~ Accommodates+Bathrooms+ Bedrooms+Price+Guests.Included+ Extra.People+ neighb_id, data = train_data_clean)
summary(modelo_metros_cuadrados_filtrado) "" --> se ha visto que eliminando los outliers, estamos eliminado todos los puntos de uno de los clusters. Por lo que no puede ser por ahi.

```

15. Si tuvieramos un anuncio de un apartamento para 6 personas (Accommodates), con 1 baño, con un precio de 80€/noche y 3 habitaciones en el barrio de Sol, con 3 camas y un review de 80. ¿Cuantos metros cuadrados tendría? Si tu modelo necesita algúna variable adicional puedes inventartela dentro del rango de valores del dataset. ¿Como varía sus metros cuadrados con cada habitación adicional?

```{r}

datos <- data.frame(Accommodates = 6, Bathrooms= 1, Price = 80, Bedrooms= 3, Guests.Included = 6, Extra.People=0, neighb_id = "2", Review.Scores.Rating = 80)

mi_apartamento <- predict(modelo_metros_cuadrados, newdata=datos, interval="confidence")
cat("El apartamento tendria:", mi_apartamento[1], "m^2")

#Mirando el summary, puedes ver el coeficiente

cat("\nCada habitacion aumenta el precio:", modelo_metros_cuadrados$coefficients['Bedrooms'], "€")
```

------------------------------------------------------------------------

16. Rellenar los Square.Meters con valor NA con el estimado con el modelo anterior.

```{r}

df_madrid_completo <- df_madrid |> mutate(Square.Meters = ifelse(is.na(Square.Meters),predict(modelo_metros_cuadrados, newdata = df_madrid),Square.Meters))

df_madrid_completo$Square.Feet<-NULL

df_madrid_completo

```

------------------------------------------------------------------------
